ğŸš— ìš´ì „ì ìƒíƒœ ì¸ì‹ì„ ìœ„í•œ CNN ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ
![alt text](https://img.shields.io/badge/AI-Deep%20Learning-blue.svg)

![alt text](https://img.shields.io/badge/Framework-TensorFlow/Keras-orange.svg)

![alt text](https://img.shields.io/badge/Python-3.8+-yellow.svg)

![alt text](https://img.shields.io/badge/Publication-KJAI-brightgreen.svg)

<br>
ìš´ì „ìì˜ ì•ˆì „ì„ ìœ„í•œ ìƒˆë¡œìš´ ëˆˆ, ë©€í‹°ëª¨ë‹¬ AIê°€ ìš´ì „ìì˜ ë¯¸ì„¸í•œ ìƒíƒœ ë³€í™”ê¹Œì§€ ê°ì§€í•˜ì—¬ ì‚¬ê³ ë¥¼ ì˜ˆë°©í•©ë‹ˆë‹¤.
ë³¸ í”„ë¡œì íŠ¸ëŠ” ìš´ì „ìì˜ ì–¼êµ´, ìì„¸, ê·¸ë¦¬ê³  ì£¼ë³€ ì†Œë¦¬ ë°ì´í„°ë¥¼ ë™ì‹œì— ë¶„ì„í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í†µí•´ **99.9%**ì˜ ì •í™•ë„ë¡œ ìš´ì „ì ìƒíƒœë¥¼ ì¸ì‹í•˜ëŠ” ì‹œìŠ¤í…œì„ ì œì•ˆí•©ë‹ˆë‹¤. On-Device AI ì ìš©ì„ ëª©í‘œë¡œ, ê°„ë‹¨í•œ ì¥ë¹„ë§Œìœ¼ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

<br>
ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)
Category	Stack
Environment	
![alt text](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
 ![alt text](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=Jupyter&logoColor=white)
Deep Learning	
![alt text](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white)
 ![alt text](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=Keras&logoColor=white)
Data Processing	
![alt text](https://img.shields.io/badge/Numpy-013243?style=for-the-badge&logo=numpy&logoColor=white)
 ![alt text](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
 ![alt text](https://img.shields.io/badge/Librosa-FF69B4?style=for-the-badge)
Visualization	
![alt text](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge&logo=matplotlib&logoColor=white)
ğŸš€ ëª¨ë¸ ì•„í‚¤í…ì²˜ (Model Architecture)
ë³¸ í”„ë¡œì íŠ¸ëŠ” 3ê°œì˜ ì…ë ¥ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬ í›„ ê²°í•©í•˜ëŠ” ë©€í‹°-ì…ë ¥ CNN ëª¨ë¸ì…ë‹ˆë‹¤.

Layer	Specifications
Input	Input 1: Driver Face Image (227x227x3)<br>Input 2: Driver State Image (227x227x3)<br>Input 3: Sound Spectrogram (227x227x3)
Conv 1	Filter: 96, Kernel: (11x11), Stride: 4 -> Output: (55x55x96)
Max Pooling 1	Pool size: (3x3), Stride: 2 -> Output: (27x27x96)
Conv 2	Filter: 256, Kernel: (5x5), Padding: same -> Output: (27x27x256)
Max Pooling 2	Pool size: (3x3), Stride: 2 -> Output: (13x13x256)
Concatenate	3ê°œ ì…ë ¥ ìŠ¤íŠ¸ë¦¼ì˜ ì¶œë ¥ì„ ê²°í•© -> Output: (13x13x768)
Conv 3	Filter: 640, Kernel: (3x3), Padding: same -> Output: (13x13x640)
Conv 4	Filter: 640, Kernel: (3x3), Padding: same -> Output: (13x13x640)
Conv 5	Filter: 384, Kernel: (3x3), Padding: same -> Output: (13x13x384)
Max Pooling 3	Pool size: (3x3), Stride: 2 -> Output: (6x6x384)
Flatten	Output: 13824
FC Layer 1	Neurons: 4096, Dropout: 0.5
FC Layer 2	Neurons: 4096, Dropout: 0.5
Output Layer	Neurons: 6, Activation: Softmax
ğŸ“Š ë°ì´í„°ì…‹ ë° ì „ì²˜ë¦¬ (Dataset & Preprocessing)
í•­ëª© (Item)	ì‚¬ì–‘ (Specification)
ì´ ë°ì´í„° ìˆ˜	18,900ê°œ (Train: 12,600 / Test: 6,300)
í´ë˜ìŠ¤	6ê°€ì§€ ìƒíƒœ (ì •ìƒ, ê¸°ì ˆ, ì¡¸ìŒ, ë†€ëŒ, ë¶„ë…¸, ë¶ˆì•ˆ)
ì…ë ¥ ë°ì´í„°	(1) ìš´ì „ì ì–¼êµ´ ì´ë¯¸ì§€, (2) ìš´ì „ì ìì„¸ ì´ë¯¸ì§€, (3) ì†Œë¦¬ ìŠ¤í™íŠ¸ë¡œê·¸ë¨
ì´ë¯¸ì§€ ì „ì²˜ë¦¬	227x227 í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”
ì‚¬ìš´ë“œ ì „ì²˜ë¦¬	2ì´ˆ ê¸¸ì´ì˜ ìŒì„± íŒŒì¼ì„ Mel Spectrogramìœ¼ë¡œ ë³€í™˜ í›„ ì´ë¯¸ì§€í™”
ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ (Experimental Results)
ëª¨ë¸ (Model)	ì…ë ¥ ë°ì´í„° (Input Data)	ì •í™•ë„ (Accuracy)
ResNet50	Driver face + state (ì´ì¤‘ ì…ë ¥)	81.0% ~ 85.7%
Xception	Driver face + state (ì´ì¤‘ ì…ë ¥)	76.8% ~ 87.8%
Our CNN (ì œì•ˆ ëª¨ë¸)	Driver face + state (ì´ì¤‘ ì…ë ¥)	75.8%
Our CNN (ì œì•ˆ ëª¨ë¸)	Driver face + state + sound (ì‚¼ì¤‘ ì…ë ¥)	ğŸ† 99.9%
<p align="center">
<img src="path/to/your/graph-image.png" width="800">
<br>
<em>Figure: ë©€í‹°-ì…ë ¥ CNNì˜ í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„. ì‚¼ì¤‘ ì…ë ¥ì—ì„œ 99.9% ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤.</em>
</p>
ğŸ§‘â€ğŸ’» íŒ€ì› (Our Team)
ì´ë¦„ (Name)	ì—­í•  (Role)
ê°•ì§€ìˆ˜, ê¹€ìˆ˜ì•„, í•œê¸°ì¤€	ë ˆí¼ëŸ°ìŠ¤ ì¡°ì‚¬ ë° ë³´ê³ ì„œ ì‘ì„±
ì‹ ìˆ˜ì•„, ì—¬í™˜ì„œ	ë¹„êµ ëª¨ë¸(ResNet50, Xception) ì—°êµ¬ ë° ì‹¤í—˜
ì´ë™ì—°, ì´ì •í˜„	ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬
ğŸ“œ ë…¼ë¬¸ ë° ì¸ìš© (Citation)
ë³¸ í”„ë¡œì íŠ¸ëŠ” í•œêµ­ì„±ì„œëŒ€í•™êµì˜ ì§€ì›ì„ ë°›ì•„ ìˆ˜í–‰ë˜ì—ˆìœ¼ë©°, ì—°êµ¬ ê²°ê³¼ëŠ” KJAI (Korean Journal of Artificial Intelligence) ì— ê²Œì¬ë˜ì—ˆìŠµë‹ˆë‹¤.

code
Code
Sooah SHIN, Jisu KANG, Sooah KIM, Hwanseo YEO, Dongyeon LEE, Jeongjyun LEE, Gijun HAN, Jinho HAN. (2025). "A study on driver state recognition using CNN-based multimodal multi-input learning". Korean Journal of Artificial Intelligence, xx(xx), xx-xx.
